{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Purpose of Notebook\n",
    "The goal of this code is to:\n",
    "- Create models for predicting mass using a set of parameters:\n",
    "    - Effective Temperature\n",
    "    - Log g\n",
    "    - Iron Abundance [Fe/H]\n",
    "    - Alpha Abundance [alpha/Fe]\n",
    "    - Nitrogen Abundance [N/Fe]\n",
    "    - Oxygen Abundance [O/Fe]\n",
    "- The model will be created using two datasets\n",
    "\n",
    "- Use K2 model to predict the mass for APOGEE and GALAH\n",
    "- Use APOKSAC model to predict mass for APOGEE\n",
    "\n",
    "A good question is: why do all of this?\n",
    "- Although the datasets used have their own mass prediction model, they are for general purposes\n",
    "- Since we are interested specifically in low mass stars up to 2.5 solar masses, we want more specific prediction of the stars masses\n",
    "- After using the model, we should also compare the distribution predicted by both models to see if the different models predict similar distribution of masses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K2 Model\n",
    "First, we seperate the data into a set of data used for training and one for verifying the fit out the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = data Y = mass\n",
    "X = []\n",
    "y = []\n",
    "# The parameters we will be using to create the model\n",
    "features = [\"teff\", \"logg\", \"fe_h\", \"al_fe\", \"c_fe\", \"n_fe\", \"o_fe\"]\n",
    "# Using 80% of the data to train the model and use 20% to verify it\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Regression (RFR)\n",
    "The first model we will use to predict the mass is Random Forest Regression.\n",
    "We will need to access the fit of our model.\n",
    "To do this, we will assess the mean squared error (square rooted) and correlation coefficient."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the model\n",
    "seed = 0 # Make sure results are replicable\n",
    "k2_model_RFR = RandomForestRegressor(n_estimators=200, random_state=seed)\n",
    "k2_model_RFR.fit(X_train, y_train)\n",
    "y_pred_RFR = k2_model_RFR.predict(X_test)\n",
    "# Determine whether the model\n",
    "score_RFR = np.sqrt(mean_absolute_error(y_pred_RFR, y_test))\n",
    "corr_RFR = np.corrcoef(y_test, y_pred_RFR)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initial parameters to create the model:\n",
    "- `n_estimator = 200`\n",
    "- `train_size = 0.8`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Polynomial Regression (PR)\n",
    "The second model we will use to predict the mass is polynomial regression.\n",
    "While this model runs into the problem of some assumptions not being satisfied such as the need for variables to be independent (mass/log gravity is typically correlated with things such as effective temperature) and the parameters not being additive, it is nonetheless a standard model worth using.\n",
    "\n",
    "The code is largely inspired by [Data36 guide](https://data36.com/polynomial-regression-python-scikit-learn/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the model\n",
    "poly = PolynomialFeatures(degree=5, include_bias=False)\n",
    "poly_features = poly.fit_transform(X_train)\n",
    "k2_model_PR = LinearRegression()\n",
    "# Train the model\n",
    "k2_model_PR.fit(poly_features, y_train)\n",
    "# Test the model\n",
    "y_pred_PR = k2_model_PR.predict(X_test)\n",
    "score_PR = np.sqrt(mean_absolute_error(y_pred_PR, y_test))\n",
    "corr_PR = np.corrcoef(y_test, y_pred_PR)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initial parameters to create the model:\n",
    "- `degree = 5`\n",
    "    - The choice of degree is arbitrary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K2 and GALAH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K2 and APOGEE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# APOKSAC Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# APOKSAC and"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
